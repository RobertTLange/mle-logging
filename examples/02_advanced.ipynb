{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/RobertTLange/mle-logging/blob/main/examples/02_advanced.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "from mle_logging import MLELogger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Log Different Random Seeds for Same Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you provide a .json file path and a seed_id, the log will be created in a sub-directory.\n",
    "\n",
    "Furthermore, the .json file will be copied for reproducibility.\n",
    "\n",
    "Multiple simultanous runs (different seeds) can now log to the same directory. Everything else remains the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate logging to experiment_dir for two random seeds\n",
    "log_seed_1 = MLELogger(time_to_track = ['num_updates', 'num_epochs'],\n",
    "                       what_to_track = ['train_loss', 'test_loss'],\n",
    "                       experiment_dir = \"multi_seed_dir/\",\n",
    "                       config_fname = \"config_1.json\",     # Provide path to .json config\n",
    "                       seed_id = \"seed_1\")                 # Provide some seed identifier (str)   \n",
    "\n",
    "log_seed_2 = MLELogger(time_to_track = ['num_updates', 'num_epochs'],\n",
    "                       what_to_track = ['train_loss', 'test_loss'],\n",
    "                       experiment_dir = \"multi_seed_dir/\",\n",
    "                       config_fname = \"config_1.json\",     # Provide path to .json config\n",
    "                       seed_id = \"seed_2\")                 # Provide some seed identifier (str)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save some time series statistics\n",
    "time_tic = {'num_updates': 10,\n",
    "            'num_epochs': 1}\n",
    "stats_tic = {'train_loss': 0.1234,\n",
    "             'test_loss': 0.1235}\n",
    "\n",
    "# Update the log with collected data & save them to .hdf5\n",
    "log_seed_1.update(time_tic, stats_tic, save=True)\n",
    "log_seed_2.update(time_tic, stats_tic, save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['seed_1', 'seed_2'], array([0.1234], dtype=float32))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, datetime\n",
    "from mle_logging import merge_seed_logs, load_log\n",
    "\n",
    "timestr = datetime.datetime.today().strftime(\"%Y-%m-%d\")[2:]\n",
    "experiment_dir = f\"multi_seed_dir/{timestr}_config_1/\"\n",
    "merged_path = os.path.join(experiment_dir, \"logs\", \"seed_aggregated.hdf5\")\n",
    "\n",
    "# Merge different random seeds into one .hdf5 file\n",
    "merge_seed_logs(merged_path, experiment_dir)\n",
    "\n",
    "# Load the merged log - Individual seeds can be accessed via log.seed_1, etc.\n",
    "log = load_log(experiment_dir)\n",
    "log.eval_ids, log.seed_1.stats.train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Only single aggregated configuration or random seed loaded.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, odict_keys(['mean', 'std', 'p50', 'p10', 'p25', 'p75', 'p90']))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the merged log and aggregate over random seeds (compute stats)\n",
    "log = load_log(experiment_dir, aggregate_seeds=True)\n",
    "log.eval_ids, log.stats.train_loss.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log Different Configurations with Different Random Seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate logging to experiment_dir for two .json configurations and two seeds\n",
    "log_c1_s1 = MLELogger(time_to_track = ['num_updates', 'num_epochs'],\n",
    "                      what_to_track = ['train_loss', 'test_loss'],\n",
    "                      experiment_dir = \"multi_config_dir/\",\n",
    "                      config_fname = \"config_1.json\",     # Provide path to .json config\n",
    "                      seed_id = \"seed_1\")                 # Provide some seed identifier (str)   \n",
    "\n",
    "log_c1_s2 = MLELogger(time_to_track = ['num_updates', 'num_epochs'],\n",
    "                      what_to_track = ['train_loss', 'test_loss'],\n",
    "                      experiment_dir = \"multi_config_dir/\",\n",
    "                      config_fname = \"config_1.json\",     # Provide path to .json config\n",
    "                      seed_id = \"seed_2\")                 # Provide some seed identifier (str)   \n",
    "\n",
    "log_c2_s1 = MLELogger(time_to_track = ['num_updates', 'num_epochs'],\n",
    "                      what_to_track = ['train_loss', 'test_loss'],\n",
    "                      experiment_dir = \"multi_config_dir/\",\n",
    "                      config_fname = \"config_2.json\",     # Provide path to .json config\n",
    "                      seed_id = \"seed_1\")                 # Provide some seed identifier (str)   \n",
    "\n",
    "log_c2_s2 = MLELogger(time_to_track = ['num_updates', 'num_epochs'],\n",
    "                      what_to_track = ['train_loss', 'test_loss'],\n",
    "                      experiment_dir = \"multi_config_dir/\",\n",
    "                      config_fname = \"config_2.json\",     # Provide path to .json config\n",
    "                      seed_id = \"seed_2\")                 # Provide some seed identifier (str)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the log with collected data & save them to .hdf5\n",
    "log_c1_s1.update(time_tic, stats_tic, save=True)\n",
    "log_c1_s2.update(time_tic, stats_tic, save=True)\n",
    "log_c2_s1.update(time_tic, stats_tic, save=True)\n",
    "log_c2_s2.update(time_tic, stats_tic, save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge different random seeds for each config into separate .hdf5 file\n",
    "merge_seed_logs(f\"multi_config_dir/{timestr}_config_1/logs/config_1.hdf5\", \n",
    "                f\"multi_config_dir/{timestr}_config_1/\")\n",
    "merge_seed_logs(f\"multi_config_dir/{timestr}_config_2/logs/config_2.hdf5\", \n",
    "                f\"multi_config_dir/{timestr}_config_2/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate the different merged configuration .hdf5 files into single meta log\n",
    "from mle_logging import merge_config_logs\n",
    "merge_config_logs(experiment_dir = \"multi_config_dir/\",\n",
    "                  all_run_ids = [\"config_1\", \"config_2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['config_2', 'config_1'],\n",
       " odict_keys(['mean', 'std', 'p50', 'p10', 'p25', 'p75', 'p90']))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Afterwards load in the meta log object\n",
    "from mle_logging import load_meta_log\n",
    "meta_log = load_meta_log(\"multi_config_dir/meta_log.hdf5\")\n",
    "meta_log.eval_ids, meta_log.config_1.stats.test_loss.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['config_1_seed_1', 'config_1_seed_2', 'config_2_seed_1', 'config_2_seed_2']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_log = load_meta_log(\"multi_config_dir/meta_log.hdf5\", aggregate_seeds=False)\n",
    "meta_log.eval_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logging Every k-th Checkpoint Update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate logging to experiment_dir\n",
    "import numpy as np\n",
    "model = {\"layer_1\": {\"w\": np.random.normal(0, 1, (784, 512)),\n",
    "                     \"b\": np.random.normal(0, 1, (512,))}}\n",
    "\n",
    "log = MLELogger(time_to_track = ['num_updates', 'num_epochs'],\n",
    "                what_to_track = ['train_loss', 'test_loss'],\n",
    "                experiment_dir = 'every_k_dir/',\n",
    "                model_type = 'jax',\n",
    "                ckpt_time_to_track = 'num_updates',\n",
    "                save_every_k_ckpt = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['every_k_dir/models/every_k/21-08-06_no_seed_provided_k_1.pkl',\n",
       "  'every_k_dir/models/every_k/21-08-06_no_seed_provided_k_3.pkl'],\n",
       " [10, 30])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_tic = {'num_updates': 10, 'num_epochs': 1}\n",
    "log.update(time_tic, stats_tic, model, save=True)\n",
    "\n",
    "time_tic = {'num_updates': 20, 'num_epochs': 1}\n",
    "log.update(time_tic, stats_tic, model, save=True)\n",
    "\n",
    "time_tic = {'num_updates': 30, 'num_epochs': 1}\n",
    "log.update(time_tic, stats_tic, model, save=True)\n",
    "\n",
    "time_tic = {'num_updates': 40, 'num_epochs': 1}\n",
    "log.update(time_tic, stats_tic, model, save=True)\n",
    "\n",
    "log.every_k_ckpt_list, log.every_k_storage_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logging Top-k Checkpoints Based on Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate logging to experiment_dir\n",
    "log = MLELogger(time_to_track = ['num_updates', 'num_epochs'],\n",
    "                what_to_track = ['train_loss', 'test_loss'],\n",
    "                experiment_dir = \"top_k_dir/\",\n",
    "                model_type = 'jax',\n",
    "                ckpt_time_to_track = 'num_updates',\n",
    "                save_top_k_ckpt = 2,\n",
    "                top_k_metric_name = \"test_loss\",\n",
    "                top_k_minimize_metric = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.09, 0.11], [30, 20])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_tic = {'num_updates': 10, 'num_epochs': 1}\n",
    "stats_tic = {'train_loss': 0.1234, 'test_loss': 0.1235}\n",
    "log.update(time_tic, stats_tic, model, save=True)\n",
    "\n",
    "time_tic = {'num_updates': 20, 'num_epochs': 1}\n",
    "stats_tic = {'train_loss': 0.1234, 'test_loss': 0.11}\n",
    "log.update(time_tic, stats_tic, model, save=True)\n",
    "\n",
    "time_tic = {'num_updates': 30, 'num_epochs': 1}\n",
    "stats_tic = {'train_loss': 0.1234, 'test_loss': 0.09}\n",
    "log.update(time_tic, stats_tic, model, save=True)\n",
    "\n",
    "time_tic = {'num_updates': 40, 'num_epochs': 1}\n",
    "stats_tic = {'train_loss': 0.1234, 'test_loss': 0.12}\n",
    "log.update(time_tic, stats_tic, model, save=True)\n",
    "\n",
    "log.top_k_performance, log.top_k_storage_time"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mle-toolbox",
   "language": "python",
   "name": "mle-toolbox"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
